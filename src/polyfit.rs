use ndarray::{s, Array0, Array1, Array2, Array, Axis, ScalarOperand};
use ndarray_linalg::{Inverse, LeastSquaresSvd, Scalar, Lapack};

use std::ops::{Range, MulAssign};

use crate::Result;
use crate::math::{outer_product, vandermonde};

pub struct Polynomial<E> {
    /// Polynomial coefficients stored in order of ascending power
    coefficients: Vec<E>,
    /// Each coefficient can be associated with a standard deviation
    ///
    /// It is assured in the constructer that, if present, the length of `standard_deviation`
    /// is equal to the length of `coefficients`
    standard_deviation: Option<Vec<E>>,
    /// If the polynomial was generated by a fit, a window can be attached which
    /// contains the range of the underlying data
    window: Option<Range<E>>,
}

impl<E: Scalar> From<FitResult<E>> for Polynomial<E> {
    fn from(value: FitResult<E>) -> Self {
        Self {
            coefficients: value.solution.into_raw_vec(),
            standard_deviation: Some(value.covariance.diag().mapv(ndarray_linalg::Scalar::sqrt).into_raw_vec()),
            window: Some(value.window),
        }
    }
}

pub struct FitResult<E: Scalar> {
    solution: Array1<E>,
    covariance: Array2<E>,
    singular_values: Array1<E::Real>,
    rank: i32,
    residual_sum_of_squares: Option<Array0<E::Real>>,
    window: Range<E>,
}

#[derive(Copy, Clone, PartialEq, Eq)]
pub enum Scaling {
    Scaled,
    Unscaled,
}

pub fn polyfit<E: Copy + Lapack + MulAssign + Ord + Scalar + ScalarOperand>(
    x: &[E],
    y: &[E],
    degree: usize,
    maybe_weights: Option<&[E]>,
    covariance: Scaling,
) -> Result<FitResult<E>> {
    let vander = vandermonde(x, degree)?;
    let mut lhs: Array2<E> = vander.to_owned();
    let mut rhs: Array1<E> = Array::from_iter(y.iter().copied()).into_shape(x.len())?;
    if let Some(weights) = maybe_weights {
        let weights: Array1<E> =
            Array::from_iter(weights.iter().copied()).into_shape(x.len())?;
        rhs *= &weights;

        for (ii, weight) in weights.iter().enumerate() {
            let mut slice = lhs.slice_mut(s![ii, ..]);
            slice *= *weight;
        }
    }

    let scaling: Array1<E> = lhs
        .mapv(|val| val.powi(2))
        .sum_axis(Axis(0))
        .mapv(ndarray_linalg::Scalar::sqrt);

    lhs /= &scaling;
    let result = lhs.least_squares(&rhs)?;
    let solution = (&result.solution.t() / &scaling).t().to_owned();

    let covariance_matrix = (lhs.t().dot(&lhs)).inv()?;
    let outer_prod_of_scaling = outer_product(&scaling, &scaling)?;
    let mut covariance_matrix = covariance_matrix / outer_prod_of_scaling;
    if covariance == Scaling::Scaled {
        let factor = result
            .residual_sum_of_squares
            .as_ref()
            .unwrap()
            .mapv(|re| E::from_real(re) / E::from(x.len() - degree).unwrap());
        covariance_matrix = covariance_matrix * factor;
    };

    let x_min = x.iter().min().unwrap().to_owned();
    let x_max = x.iter().max().unwrap().to_owned();

    Ok(FitResult {
        solution,
        covariance: covariance_matrix,
        singular_values: result.singular_values,
        rank: result.rank,
        residual_sum_of_squares: result.residual_sum_of_squares,
        window: x_min..x_max,
    })

}
